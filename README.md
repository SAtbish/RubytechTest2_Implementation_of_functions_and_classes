### Как запустить выполнение тасков

#### Docker
`docker compose up`

#### Без докера
`poetry install`
`poetry shell`
`python main,py`

## Пояснения ко всем тестовым задачам

### task_a
Т.к. в условии не было сказано о проверке доступности репозитория была произведена только валидация по правилам с сайта GitHub.
Правила описал в самом файле.

### task_b
В качестве ключа было проверено большое количество разных объектов, например функции, классы с переопределённым методом `__hash__` и другие.
Сортировать полученный словарь имеющий в ключах различные типы пришлось вручную разделив их и заново собрав в конечном овтете.

### task_c
Т.к. в ТЗ было чётко сказано, что функция(`map+lambda`) принимает список только из строк и цифр, была написана валидирующая функция списка значений.
Данные, которые не строка и не цифра, были откинуты.

### task_d
Самая интересная задача. Реализовал с помощью собственной реализации асинхронного генератора с установкой количества параллельных запросов, которые крутятся одновременно.
За счёт генератора мы получаем данные по готовности, а не когда все выполнятся(как в gather), что позволяет нам увеличить производительность.
Рекорд: `3.59` сек на обычном железе(`i5, 1650`).
В среднем `4.5` сек

### task_e_and_f
Распаршиваю полученный текст с помощью регулярки. Я считаю словом слова, в которых есть хотя бы одна буква и опционально числа и `_`(например для логинов `leha_shumov`).
Далее выполняю все нужные действия либо вызовом всех функция сразу(метод `analyze()`), либо каждой по отдельности для замера времени.
Написан декоратор класса(реальный декоратор класса, который оборачивает в отдельный класс, а не обёртка к каждой функции).
